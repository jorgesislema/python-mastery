# ğŸ“Œ ExploraciÃ³n de Datos (EDA) y TransformaciÃ³n (ETL) en Python ğŸ

La **ExploraciÃ³n de Datos (EDA)** y la **ExtracciÃ³n, TransformaciÃ³n y Carga (ETL)** son procesos fundamentales en la ciencia de datos y en la ingenierÃ­a de datos. Antes de entrenar un modelo de Machine Learning o realizar un anÃ¡lisis, es crucial entender los datos, limpiarlos y transformarlos correctamente. ğŸ“ŠğŸ”

---

## 1ï¸âƒ£ Â¿QuÃ© es la ExploraciÃ³n de Datos (EDA)? ğŸ¤”

EDA (**Exploratory Data Analysis**) es el proceso de analizar y comprender un conjunto de datos a travÃ©s de:
- **Visualizaciones**: Â¿CÃ³mo estÃ¡ distribuida la informaciÃ³n? ğŸ“Š
- **EstadÃ­sticas descriptivas**: Â¿CuÃ¡les son los valores mÃ¡s comunes? Â¿Existen valores atÃ­picos (outliers)? ğŸ“ˆ
- **Relaciones entre variables**: Â¿CÃ³mo se correlacionan los datos? ğŸ”„
- **Patrones ocultos**: Â¿Existen grupos naturales en los datos? ğŸ“Œ

### ğŸ”¹ Diferencias entre EDA y ETL

| CaracterÃ­stica | EDA (ExploraciÃ³n de Datos) | ETL (ExtracciÃ³n, TransformaciÃ³n y Carga) |
|--------------|------------------------|-------------------------------|
| **Objetivo** | Comprender los datos y encontrar patrones, tendencias y anomalÃ­as. | Transformar los datos para hacerlos utilizables en modelos o bases de datos. |
| **Fases** | InspecciÃ³n, limpieza, visualizaciÃ³n, anÃ¡lisis estadÃ­stico. | ExtracciÃ³n desde mÃºltiples fuentes, transformaciÃ³n y limpieza, carga en bases de datos. |
| **Herramientas Principales** | Pandas, NumPy, Seaborn, Matplotlib. | Pandas, SQL, PySpark, Airflow. |
| **Ejemplo de Uso** | Verificar valores nulos, detectar outliers, explorar correlaciones. | Convertir formatos de datos, normalizar columnas, cargar datos en una base de datos. |
| **Momento en el Proceso** | Se realiza antes del modelado para conocer los datos. | Se realiza para preparar los datos y hacerlos accesibles para anÃ¡lisis posteriores. |

### ğŸ”¹ Pasos Claves en un AnÃ¡lisis EDA:

### 1ï¸âƒ£ Cargar los Datos ğŸ“‚
```python
import pandas as pd
import numpy as np

df = pd.read_csv("datos.csv")  # Cargar un archivo CSV
print(df.head())  # Mostrar las primeras filas
```

ğŸ“Œ **Posibles Problemas:**
âŒ **El archivo CSV tiene delimitadores diferentes** â†’ Usa `pd.read_csv("archivo.csv", delimiter=';')`  
âŒ **Columnas mal nombradas** â†’ RenÃ³mbralas con `df.rename(columns={'col_antigua': 'col_nueva'}, inplace=True)`

---

### 2ï¸âƒ£ Verificar la Estructura del Dataset ğŸ—ï¸
```python
print(df.info())  # Muestra tipos de datos y valores nulos
print(df.describe())  # EstadÃ­sticas generales (media, mÃ­nimo, mÃ¡ximo...)
```
ğŸ“Œ **Posibles Problemas:**
âŒ **Columnas categÃ³ricas aparecen como numÃ©ricas** â†’ Convierte con `df["col"] = df["col"].astype(str)`
âŒ **Valores incorrectos en fechas** â†’ Convierte con `df["fecha"] = pd.to_datetime(df["fecha"])`

---

### 3ï¸âƒ£ Identificar Valores Nulos ğŸ”
```python
print(df.isnull().sum())  # Conteo de valores nulos por columna
```

ğŸ“Œ **Posibles Soluciones:**
âœ… **Eliminar valores nulos:**
```python
df = df.dropna()
```
âœ… **Rellenar valores nulos:**
```python
df.fillna(df.mean(), inplace=True)  # Rellenar con la media de la columna
```
âœ… **Reemplazar valores vacÃ­os en columnas categÃ³ricas:**
```python
df["col_categ"] = df["col_categ"].fillna("Desconocido")
```

---

### 4ï¸âƒ£ Detectar Duplicados ğŸ§
```python
print(df.duplicated().sum())  # Contar filas duplicadas
df = df.drop_duplicates()
```
ğŸ“Œ **Posibles Problemas:**
âŒ **Datos ingresados varias veces** â†’ Usa `df.drop_duplicates(inplace=True)`

---

### 5ï¸âƒ£ AnÃ¡lisis de DistribuciÃ³n de Datos ğŸ“Š
```python
import seaborn as sns
import matplotlib.pyplot as plt

sns.histplot(df["edad"], bins=30, kde=True)
plt.show()
```
ğŸ“Œ **Posibles Problemas:**
âŒ **Datos sesgados** â†’ Aplicar transformaciones como `np.log(df["edad"])`
âŒ **Datos con outliers** â†’ Usar `sns.boxplot(x=df["edad"])`

---

### 6ï¸âƒ£ Correlaciones y RelaciÃ³n entre Variables ğŸ”„
```python
sns.heatmap(df.corr(), annot=True, cmap="coolwarm")
plt.show()
```
ğŸ“Œ **Posibles Problemas:**
âŒ **Columnas con baja correlaciÃ³n** â†’ Considerar eliminarlas
âŒ **Falta de datos en variables categÃ³ricas** â†’ Realizar codificaciÃ³n con `pd.get_dummies(df)`

---

## ğŸ“Œ Resumen Final ğŸ“

| Paso | DescripciÃ³n |
|------|-------------|
| **EDA** | AnÃ¡lisis, visualizaciÃ³n y limpieza de datos |
| **ETL** | Extraer, transformar y cargar datos |
| **Eliminar Nulos** | `df.fillna()`, `df.dropna()` |
| **Eliminar Duplicados** | `df.drop_duplicates()` |
| **Detectar Outliers** | Usar IQR y Boxplots |
| **Normalizar Datos** | `StandardScaler()` |
| **Guardar Datos** | `df.to_csv()`, `df.to_sql()` |

---

## ğŸ¯ Consejos Finales ğŸ¯
âœ… **Explora siempre los datos antes de analizarlos o entrenar modelos.**  
âœ… **Visualiza patrones y anomalÃ­as antes de tomar decisiones.**  
âœ… **Limpia y normaliza los datos para evitar errores en los modelos.**  
âœ… **Usa herramientas como Pandas, Seaborn y SQL para un mejor ETL.**  

